## Transaction Module

### Role in the architecture

Transaction Abstraction

This document describes the Transaction Abstraction, the innermost and most fundamental concept in the Ergon Framework. Although "transaction" is not a physical module in the codebase, it is a first-class architectural construct that every other module depends upon. It represents the core unit of meaning, responsibility, and atomicity across the entire framework.

The transaction abstraction sits at the center of the architecture, forming the nucleus around which all logic is organized. Tasks operate on transactions. Connectors fetch and produce transactions. Services retrieve, batch, stream, or serialize transactions. Telemetry tracks transaction handling. Everything else in the framework exists to move, transform, observe, or manage transactions.

The transaction is the “grain” of the system — the smallest unit of work that tasks process in a deterministic manner.

### Definition

A transaction is defined as: a single atomic unit of work that a task should process indivisibly.

This atomic unit can take many forms:

- a message from a queue  
- a record from a file  
- an event from a stream  
- an item retrieved from an API  
- a domain object  
- a structured payload  
- or even an entire batch of data that must be handled as a whole  

A transaction is intentionally kept transport-agnostic and schema-agnostic. It represents meaning, not format.

The only invariant is atomicity: a task either processes the transaction completely, or not at all.

### Transaction Object

In the framework, a transaction is represented by a concrete `Transaction` object—an immutable data structure with three fields:

- **`id`**: A unique identifier for the transaction, used for tracing and correlation across the system.
- **`payload`**: The actual data content (the domain object, message body, record, etc.).
- **`metadata`**: Optional dictionary for additional context (routing information, timestamps, checkpoints, etc.).

**Immutability Enforcement**: The `Transaction` object is **frozen** (immutable) once created. This enforces the architectural rule that transactions cannot be split or modified after construction. Once a connector creates a transaction, its structure is locked, guaranteeing that the atomic boundary defined by the external system is preserved throughout the task's processing lifecycle.

### Atomicity rules

Atomicity governs all behavior in the framework.

**3.1 A transaction must not be split.** If the upstream system declares something as a cohesive batch or unit, the framework preserves it. If the external system emits one message, that becomes one transaction; if it emits a batch of 500 items, that becomes one transaction; if it emits a streaming window, that becomes one transaction; if it emits an ETL payload chunk, that becomes one transaction. The upstream system determines the atomic boundary; the framework enforces it.

**3.2 A transaction must not be merged.** Two independent messages cannot be arbitrarily grouped into a single transaction within the framework. Grouping logic (if needed) belongs inside the service layer based on upstream semantics.

**3.3 Transaction boundaries define task semantics.** Tasks operate only on transactions. They never manipulate raw transport-specific structures.

### Why transaction-first architecture matters

A transaction-first design forces architectural clarity:

1. Tasks become pure domain logic. They process “work,” not protocols or clients.  
2. Connectors become clean boundaries. They shuttle transactions from external systems to the task and back.  
3. Services become protocol engines. They manage batching, retries, pagination, and streaming without leaking complexity upward.  
4. Scalability becomes natural. Workers scale based on transaction throughput, not external APIs.  
5. Observability becomes consistent. Each transaction can produce logs, metrics, spans, and correlation IDs without developers doing anything.  
6. Error handling becomes predictable. Because the transaction is the indivisible unit, failure handling, retries, and timeouts become uniform.  

### Transaction lifecycle in the framework

Every transaction follows a predictable life through the system:

1. **Origin.** A service fetches or receives a unit of work from an external system.
2. **Construction.** The connector wraps that unit into an immutable `Transaction` object, assigning a unique `id`, placing the data in `payload`, and enriching `metadata` as needed.
3. **Ingestion.** The task receives the `Transaction` object through a consumer mixin or hybrid mixin.
4. **Core Processing (`process_transaction`).** The task applies its pure, idempotent, and retryable business logic to the transaction's `payload`. This stage should focus on computation, transformation, and state changes. Successful completion of this stage marks the transaction as "logically processed."
5. **Side Effects (`hooks`).** Once the core processing succeeds, the framework invokes lifecycle hooks (`handle_process_success`). This is where non-retryable or external side effects (like notifications, secondary API calls, or cleanup) should reside. Separating these from the core logic prevents re-execution of expensive business rules if a side effect fails.
6. **Production (optional).** The task creates new `Transaction` objects for outbound emission, each with its own `id` and `payload`.
7. **Output.** The connector extracts the `payload` from outbound `Transaction` objects and passes them to its service for transmission to the external system.
8. **Telemetry.** During all these steps, logs, metrics, and spans are automatically generated and correlated using the transaction's `id`.  

The transaction is the "thread" that ties the entire workflow together, and its immutability ensures that atomic boundaries are never violated.

### Flexibility of transaction payload

While the `Transaction` object structure is standardized (`id`, `payload`, `metadata`), the **payload** field is intentionally flexible. Each connector determines what goes into the payload based on the semantics of the external system.

Examples:

- A RabbitMQ connector may place the message body in `payload`, and store routing keys in `metadata`.
- A File connector may place the file content in `payload`, and store file path and line number in `metadata`.
- A REST connector may place the API response data in `payload`, and store status codes and headers in `metadata`.
- An ETL connector may place the entire batch array in `payload`, and store batch identifiers in `metadata`.

This flexibility allows the framework to unify radically different systems under a single abstraction while preserving the immutability and atomicity guarantees of the Transaction object itself.

### Transaction as the contract between modules

The transaction is the boundary contract that ensures modules remain decoupled: tasks know only the transaction, not the protocol; connectors know how to expose transactions, not how to process them; services know how to fetch or send data as transactions, not how to interpret them; telemetry knows how to annotate transaction events, not how to handle business logic. This enables complete modularity.

### Transactions and scaling

Scaling happens along transaction boundaries: more workers mean more transactions processed in parallel; async tasks allow more transactions to be awaited concurrently; sharded connectors enable more distributed transaction ingestion; batching allows large transactions to be handled atomically; rate limits are controlled by services, not tasks. Because everything centers on transactions, scaling strategies remain consistent.

### Design rationale

The transaction abstraction exists to provide architectural stability, unify heterogeneous external systems, simplify task development, reduce protocol leakage, improve observability, standardize concurrency, and enforce a domain-centric design. It ensures that the Ergon Framework remains clean, composable, and maintainable as it grows.

### Conclusion

The transaction abstraction is the core conceptual pillar of the Ergon Framework. It defines how work is represented, how it flows through the system, and how the framework enforces boundaries between domain logic, transport logic, and protocol mechanics.

By defining the transaction as the atomic unit of work—and by treating everything else as an adapter around it—the framework achieves clarity, scalability, maintainability, composability, and extreme extensibility. All other modules (task, connector, service, telemetry) exist to support the correct ingestion, processing, production, transportation, and observation of transactions.
