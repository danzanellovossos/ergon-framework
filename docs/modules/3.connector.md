## Connector Module

### Overview

The Connector Module defines the **transaction gateways** of the Ergon Framework. A **Connector** is a structured wrapper around a **Service** that adapts it to the framework's transaction flow interface.

Connectors exist to:

1. **Shield tasks** from transport mechanics.
2. **Standardize** the way transactions enter and exit the system (`fetch_transactions` and `dispatch_transactions` methods).
3. **Preserve atomicity** at the system boundary.

While Services handle the "how" of talking to external systems, Connectors handle the "when" and "what" of the transaction pipeline.

### Composition Pattern

A central design principle is **Composition**:

- Every Connector holds exactly one Service instance.
- The Connector delegates all low-level operations to that Service.
- The Connector adapts the Service's capabilities into the `fetch_transactions` and `dispatch_transactions` contract.

This means a Connector is never a standalone implementation of a protocol. It is always a bridge between the generic Task Framework and a specific Service implementation.

**The Transaction Object as the Interface**: The connector's primary role is to create and unwrap `Transaction` objects. When fetching, it takes raw data from the service and constructs an immutable `Transaction` with a unique `id`, the data in `payload`, and any routing/context in `metadata`. When producing, it receives a `Transaction` from the task and extracts the `payload` to send via the service. This ensures that tasks only interact with the standardized transaction interface, while services remain focused on protocol mechanics.

### Responsibilities

A connector exposes exactly two mandatory responsibilities:

1. **Fetch Transactions**: Pull atomic units of work from the underlying Service and wrap them into `Transaction` objects. The connector acts as the **adapter layer** that transforms service-specific data (messages, records, events) into the standardized `Transaction` interface that tasks expect. It assigns a unique `id` to each transaction, places the service data into the `payload` field, and may enrich `metadata` with routing or context information.
2. **Dispatch Transactions**: Accept a list of `Transaction` objects from a Task and extract the `payload` (and optionally `metadata`) to hand to the underlying Service for emission. The connector unwraps the transaction envelope and delegates the actual transmission to the service.

In addition to these mandatory responsibilities, a connector may provide auxiliary capabilities such as transaction resolution by identifier or count retrieval. These capabilities do not alter the connector's fundamental role as a transaction gateway. They extend its utility for specialized execution modes without introducing new responsibilities or changing the two-responsibility contract.

Connectors must never embed business logic, transformation pipelines, or conditional rules. They exist solely as adaptors that bridge the gap between the service's raw data format and the task's transaction interface.

### Connector Interface

The module defines a clear interface for synchronous and asynchronous connectors. The interface distinguishes between mandatory and optional capabilities.

#### Mandatory Capabilities

Every connector must implement:

- **Fetch**: Retrieve a batch of transactions from the external system.
- **Dispatch**: Send a list of transactions to the external system.

These capabilities define the minimum contract for participation in the framework's execution model. A connector that does not implement both is not a valid transaction gateway.

#### Optional Capabilities

A connector may additionally implement:

- **Resolve by Identifier**: Retrieve a single transaction by its unique identifier.
- **Count**: Return the total number of available transactions in the external system.

These capabilities are not required for standard task execution. They extend the connector's utility for specialized scenarios such as targeted reprocessing, operational inspection, or recovery workflows.

If a connector does not implement an optional capability, the corresponding execution mode or query is unavailable for that connector. The framework does not provide fallback behavior; optional capabilities are either supported or absent.

### Transactions and atomicity

A transaction, as consumed or produced by a connector, represents an atomic unit of work. The connector must never modify atomicity. If the external system defines a batch of 10,000 records as a single indivisible unit, the connector must surface that batch intact as a single `Transaction` object (with the entire batch in the `payload` field). The connector simply reflects the transactional semantics of upstream and downstream systems without splitting or merging units of work.

Because the `Transaction` object is immutable once created, the connector's atomicity guarantee is enforced at the type level: once a transaction is constructed and passed to the task, it cannot be modified, ensuring that the atomic boundary defined by the external system is preserved throughout processing.

A transaction resolved by identifier must be treated identically to one fetched via batch retrieval. The same atomicity rules apply: no splitting, no merging, no partial retrieval. The framework does not distinguish between "fetched" and "resolved" transactions after creation. Once a transaction object exists, its origin is irrelevant to the processing lifecycle.

### Transaction Resolution by Identifier (Optional Capability)

Transaction resolution by identifier is an optional capability that allows a connector to retrieve a single transaction using a known identifier. This capability exists to support targeted execution modes where the goal is to process a specific, known transaction rather than consuming from a stream or batch.

#### Purpose

Resolution by identifier serves several use cases:

- **Isolated Execution**: Process a single transaction with full lifecycle guarantees without running a consumer loop.
- **Recovery**: Re-execute a transaction that previously failed, using its identifier to retrieve it from the source system.
- **Debugging**: Isolate and process a specific transaction for diagnostic purposes.
- **Operational Intervention**: Target a particular transaction for manual reprocessing without affecting other pending work.

#### Integration with Execution Modes

Transaction resolution by identifier integrates with the Task Module's execution modes. When the framework executes a transaction by identifier, it first invokes the connector's resolution capability to retrieve the transaction, then processes that transaction through the standard task lifecycle.

Resolution does not introduce a new execution model. The resolved transaction follows the same lifecycle phases—processing, success handling, exception handling—as any other transaction. The only difference is how the transaction enters the system: by explicit resolution rather than batch retrieval.

#### Orthogonality to Consumer Loops

Resolution by identifier is entirely orthogonal to consumer loop semantics. It does not affect:

- Batch fetching behavior
- Streaming mode configuration
- Empty queue backoff policies
- Concurrency settings

When a connector supports resolution by identifier, that capability exists alongside—not instead of—the connector's standard batch retrieval. The two capabilities serve different execution contexts and do not interact.

#### Atomicity Guarantees

Resolution by identifier must return exactly one atomic transaction. Partial retrieval, multi-transaction responses, or merged results are not permitted. The returned transaction must satisfy the same immutability and atomicity requirements as any transaction created through batch fetching.

If the identifier does not correspond to a valid transaction in the external system, the resolution must fail explicitly. The connector must not return a synthetic or placeholder transaction.

#### When Resolution is Unavailable

If a connector does not implement resolution by identifier, the framework cannot execute transactions by identifier through that connector. This is not a failure condition; it simply means the connector does not support that execution mode. The connector remains fully functional for standard batch-based execution.

### Configuration

Connectors and Services are configured using declarative configuration objects:

- **ConnectorConfig**: Specifies the connector class and its initialization arguments.
- **ServiceConfig**: Specifies the service class and its initialization arguments.

This separation allows the framework to instantiate these components at runtime based on the task configuration, facilitating dependency injection into the task instance.

It is important to distinguish between the two:

- **Service**: "I know how to talk to Kafka." (Has methods like `poll()`, `commit()`, `send()`).
- **Connector**: "I know how to fetch transactions from Kafka." (Calls `service.poll()`, wraps result in `Transaction`).

**Connectors are optional.**

- If a Service is used only for enrichment (e.g., an OpenAI API client), it does not need a Connector. It can be injected directly into the Task.
- If a Service is used as a source or sink of the main workflow (e.g., a RabbitMQ consumer), it requires a Connector to plug into the framework's runner loop.

### Observability

Observability flows naturally into connectors from the runner. Connectors receive logger and tracer instances automatically and pass them to services. Tracing spans for connector instantiation, transaction fetches, and transaction productions are created upstream, ensuring full instrumentation without requiring connectors to be manually instrumented.

### Lifecycle and isolation

During execution, connectors are instantiated per worker, ensuring complete isolation between processes or async runtimes. Each worker creates its own connector and its own service instance. This makes lifecycle management easy and ensures that concurrency models are cleanly separated.

### Scaling behavior

Scaling behavior is determined entirely by the semantics of the external system and implemented inside the service. The connector does not implement scaling logic; it simply allows the runner to instantiate multiple workers whose services interact with the transport’s own scaling mechanism.

### Summary

In conclusion, the Connectors Module defines how the external world is represented as a **flow of transactions**. Its strict role boundaries preserve atomicity and ensure clean integration. By wrapping Services in a standardized interface, Connectors allow the framework to orchestrate complex pipelines without knowing the details of the underlying transport.

<br/>


