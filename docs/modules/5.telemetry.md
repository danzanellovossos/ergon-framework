## Telemetry Module

### Overview

The Telemetry Module provides a production-grade observability stack built entirely on OpenTelemetry (OTel) standards. It ensures that every task execution is observable by default without requiring developers to manually instrument their business logic.

The module unifies three pillars of observability:

1.  **Logging**: Structured logs with automatic context propagation.
2.  **Metrics**: Application-level metrics (counters, histograms, gauges) via the OTel MeterProvider.
3.  **Tracing**: Distributed tracing via the OTel TracerProvider.

### Core Philosophy: "Configure Once, Instrument Everywhere"

The Ergon Framework handles telemetry initialization automatically.
-   **Runners** initialize telemetry once per worker process/thread at startup.
-   **Tasks, Connectors, and Services** simply request a logger, tracer, or meter using standard accessors.
-   **Configuration** is declarative and decoupled from code. You can switch from Console exporters to OTLP (e.g., Jaeger/Prometheus/Tempo) by changing the configuration, not the code.

### 1. Logging

The logging subsystem wraps Python's standard `logging` library but enhances it with OTel integration.

#### Features
-   **Structured JSON Logging**: Native support for JSON output, ideal for ingestion by modern log management platforms.
-   **Context Propagation**: Automatically injects current `trace_id` and `span_id` into log records, allowing logs to be correlated with traces.
-   **Handlers**: Supports `Console`, `File`, `RotatingFile`, `TimedRotatingFile`, `JSON`, and `OTLP` handlers. The `OTLPLogHandler` allows sending logs directly to an OpenTelemetry Collector via gRPC.

### 2. Metrics

The metrics subsystem uses the OpenTelemetry `MeterProvider`. It supports push-based metric exporters via the `PeriodicExportingMetricReader`.

#### Features
-   **Periodic Exporting**: Metrics are aggregated in memory and pushed to collectors at configurable intervals.
-   **Standard Instruments**: Supports Counters, UpDownCounters, Histograms, and Gauges.
-   **Resource Attributes**: All metrics are automatically tagged with the task name, host, PID, and execution ID.

### 3. Tracing

The tracing subsystem uses the OpenTelemetry `TracerProvider`.

#### Features
-   **Samplers**: Configurable sampling (e.g., AlwaysOn, TraceIdRatioBased) to control data volume.
-   **Processors**: Support for `BatchSpanProcessor` (production) and `SimpleSpanProcessor` (debugging).
-   **Exporters**: Support for OTLP (gRPC/HTTP) and Console exporters.
-   **Automatic Context**: The framework automatically starts a root span for every transaction processed and propagates the context to Connectors and Services.

### 4. Automatic Resource Injection

To ensure every signal can be traced back to its source, the Telemetry Module automatically injects **Resource Attributes** into every LogRecord, Metric, and Span:

-   **Service Name**: The name of the task (e.g., `OrderProcessor`).
-   **Instance ID**: The unique execution ID of the runner.
-   **Process ID**: The PID of the worker.
-   **Host Name**: The hostname of the machine/pod.
-   **Host IP**: The IP address.

### 5. Configuration

Telemetry is configured via declarative configuration objects passed to the task configuration (`TaskConfig`). These objects map directly to the underlying Pydantic models:

- **LoggingConfig**: Configures handlers, formatters, filters, and log levels.
- **MetricsConfig**: Configures readers and resource attributes.
- **TracingConfig**: Configures samplers, processors, and exporters.

This separation allows operations teams to manage observability backends (switching from local files to a central collector) without modifying application code.

### Summary

The Telemetry Module removes the burden of observability from application developers. By providing a standardized, pre-configured OTel stack, it ensures that every Ergon-based system is "observable by design," providing deep visibility into distributed pipelines from day one.
